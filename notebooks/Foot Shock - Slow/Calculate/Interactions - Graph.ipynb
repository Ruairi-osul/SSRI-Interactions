{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Miniconda3\\envs\\ssri\\lib\\site-packages\\outdated\\utils.py:14: OutdatedPackageWarning: The package outdated is out of date. Your version is 0.2.1, the latest is 0.2.2.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "from ssri_interactions.interactions.loaders import BaseShockSlowInteractionsLoader\n",
    "from ssri_interactions.interactions.preprocessors import InteractionsPreprocessor\n",
    "from ssri_interactions.interactions.pairwise import PairwiseCorr\n",
    "from ssri_interactions.interactions.graph_clustering import df_to_graph\n",
    "from ssri_interactions.config import Config, ExperimentInfo\n",
    "import numpy as np\n",
    "from ssri_interactions.interactions.graph import GraphAttributes, NodeAttributes\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from ssri_interactions.io import load_derived_generic, load_distances\n",
    "from ssri_interactions.transforms.graph import GraphTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from ssri_interactions.plots import PAL_GREY_BLACK\n",
    "from scipy.stats import chi2_contingency\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import wilcoxon\n",
    "from ssri_interactions.stats import mannwhitneyu_plusplus\n",
    "import pingouin as pg\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "fig_dir = Config.fig_dir\n",
    "sns.set_theme(style=\"ticks\", context=\"paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_responders():\n",
    "    slow_responders_shock = (\n",
    "        load_derived_generic(\"slow_ts_foot_shock_unit_responders_pre_to_shock.csv\")\n",
    "        [[\"neuron_id\", \"response\"]]\n",
    "        .rename(columns={\"response\": \"response_fs_slow\"})\n",
    "    )\n",
    "    fast_responders_first_window = (\n",
    "        load_derived_generic(\"fast_fs_foot_shock_unit_responders.csv\")\n",
    "        [[\"neuron_id\", \"fs_fast_response\"]]\n",
    "    )\n",
    "    fast_responders_second_window = (\n",
    "        load_derived_generic(\"fast_fs_foot_shock_unit_responders_second_window.csv\")\n",
    "        [[\"neuron_id\", \"response_second_window\"]]\n",
    "    )\n",
    "    neuron_types = load_derived_generic(\"neuron_types.csv\")[[\"neuron_id\", \"neuron_type\", \"session_name\", \"group\"]]\n",
    "    df_responders = (\n",
    "        slow_responders_shock\n",
    "        .merge(fast_responders_first_window, how=\"outer\")\n",
    "        .merge(fast_responders_second_window, how=\"outer\")\n",
    "        .merge(neuron_types, how=\"left\")\n",
    "    )\n",
    "    return df_responders\n",
    "\n",
    "\n",
    "def get_graph_stats(session_name, bin_width, graph_transformer, block):\n",
    "        graph_attrs = GraphAttributes(distance_from_edge=\"bounded\")\n",
    "        node_attrs = NodeAttributes()\n",
    "        loader = BaseShockSlowInteractionsLoader(\n",
    "                        session_name=session_name,\n",
    "                        bin_width=bin_width,\n",
    "                        block=block,\n",
    "                    )\n",
    "        preprocessor = InteractionsPreprocessor()\n",
    "        pairwise = PairwiseCorr(rectify=True, shuffle=False)\n",
    "        spikes = preprocessor(loader())\n",
    "        df_affinity = (\n",
    "            pairwise.fit(spikes)\n",
    "            .get_adjacency_df()\n",
    "            .dropna(axis=1, thresh=5)\n",
    "            .dropna(axis=0, thresh=5)\n",
    "        )\n",
    "        G = df_to_graph(df_affinity, rename_nodes=True)\n",
    "\n",
    "        graph_stats = (\n",
    "            graph_attrs\n",
    "            .get_graph_attributes(G)\n",
    "            .assign(session_name=session_name, block=block, bin_width=bin_width)\n",
    "        )\n",
    "        node_stats = (\n",
    "            node_attrs\n",
    "            .get_node_attributes(G, node_name=\"neuron_id\")\n",
    "            .assign(session_name=session_name, block=block,  bin_width=bin_width)\n",
    "        )\n",
    "        edge_stats = (\n",
    "            graph_transformer\n",
    "            .graph_to_edge_df(G)\n",
    "            .assign(session_name=session_name, block=block, bin_width=bin_width)\n",
    "        )\n",
    "        return graph_stats, node_stats, edge_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [02:25<00:00, 36.35s/it]\n"
     ]
    }
   ],
   "source": [
    "neuron_types = load_derived_generic(\"neuron_types.csv\").loc[\n",
    "    lambda x: ~x[\"neuron_type\"].isna()\n",
    "]\n",
    "sessions = (\n",
    "    neuron_types.query(\"experiment_name == 'HAMILTON' and group in ('SAL', 'CIT')\")[\n",
    "        \"session_name\"\n",
    "    ]\n",
    "    .dropna()\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "df_distance = load_distances()\n",
    "df_ensembles = (\n",
    "    load_derived_generic(\"ensembles/fs - ensembles - true.csv\")\n",
    "    .drop_duplicates()\n",
    "    .loc[lambda x: x.neuron_id.isin(neuron_types.neuron_id.unique())]\n",
    ")\n",
    "df_ensembles[\"in_ensemble\"] = np.where(df_ensembles[\"ensemble_id\"] != \"-1\", True, False)\n",
    "\n",
    "df_responders = load_responders()\n",
    "\n",
    "graph_attrs = GraphAttributes()\n",
    "node_attrs = NodeAttributes()\n",
    "\n",
    "graph_dfs = []\n",
    "node_dfs = []\n",
    "edge_dfs = []\n",
    "\n",
    "for bin_width in tqdm((0.05, 0.1, 0.5, 1)):\n",
    "    for block in (\"pre\", \"base_shock\"):\n",
    "        g_transformer = GraphTransformer(\n",
    "            relabel_nodes=True,\n",
    "            weight_attr=\"weight\",\n",
    "            neuron_types=neuron_types,\n",
    "            df_distance=df_distance,\n",
    "            df_ensemble=df_ensembles.loc[\n",
    "                (df_ensembles[\"block\"] == block)\n",
    "                & (df_ensembles[\"bin_width\"] == bin_width)\n",
    "            ],\n",
    "        )\n",
    "        for session_name in sessions:\n",
    "            graph_stats, node_stats, edge_stats = get_graph_stats(\n",
    "                session_name, bin_width, graph_transformer=g_transformer, block=block\n",
    "            )\n",
    "            graph_dfs.append(graph_stats)\n",
    "            node_dfs.append(node_stats)\n",
    "            edge_dfs.append(edge_stats)\n",
    "\n",
    "df_graph = (\n",
    "    pd.concat(graph_dfs)\n",
    "    .reset_index(drop=True)\n",
    "    .merge(\n",
    "        neuron_types[[\"session_name\", \"group\"]].drop_duplicates(),\n",
    "    )\n",
    ")\n",
    "df_edge = (\n",
    "    pd.concat(edge_dfs)\n",
    "    .reset_index(drop=True)\n",
    "    .merge(\n",
    "        neuron_types[[\"session_name\", \"group\"]].drop_duplicates(),\n",
    "    )\n",
    ")\n",
    "df_node = (\n",
    "    pd.concat(node_dfs)\n",
    "    .reset_index(drop=True)\n",
    "    .merge(neuron_types[[\"neuron_id\",\"neuron_type\", \"group\"]].drop_duplicates())\n",
    ")\n",
    "df_node = df_node.merge(\n",
    "    df_ensembles[\n",
    "        [\n",
    "            \"neuron_id\",\n",
    "            \"in_ensemble\",\n",
    "            \"block\",\n",
    "            \"bin_width\",\n",
    "        ]\n",
    "    ],\n",
    "    how=\"left\",\n",
    ").drop_duplicates()\n",
    "df_node = df_node.merge(df_responders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = Config.derived_data_dir / \"graph\"\n",
    "\n",
    "dd.mkdir(exist_ok=True)\n",
    "\n",
    "df_graph.to_parquet(dd / \"fs - graph.parquet\", index=False)\n",
    "df_node.to_parquet(dd / \"fs - node.parquet\", index=False)\n",
    "df_edge.to_parquet(dd / \"fs - edge.parquet\", index=False)\n",
    "df_responders.to_parquet(dd / \"fs - responders.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ssri')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43cbdb6d61dab472ca36965b8e063b8466d44641e4bc0dd430fcfe888de07997"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
