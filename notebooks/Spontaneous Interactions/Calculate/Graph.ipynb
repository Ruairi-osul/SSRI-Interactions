{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Miniconda3\\envs\\ssri\\lib\\site-packages\\outdated\\utils.py:14: OutdatedPackageWarning: The package outdated is out of date. Your version is 0.2.1, the latest is 0.2.2.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "from ssri_interactions.interactions.loaders import SpontaneousActivityLoader, StateInteractionsLoader\n",
    "from ssri_interactions.interactions.preprocessors import InteractionsPreprocessor\n",
    "from ssri_interactions.interactions.pairwise import PairwiseCorr\n",
    "from ssri_interactions.interactions.graph_clustering import df_to_graph\n",
    "from ssri_interactions.config import Config, ExperimentInfo\n",
    "import numpy as np\n",
    "from ssri_interactions.interactions.graph import GraphAttributes, NodeAttributes\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from ssri_interactions.io import load_derived_generic, load_distances\n",
    "from ssri_interactions.transforms.graph import GraphTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from ssri_interactions.plots import PAL_GREY_BLACK\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "fig_dir = Config.fig_dir\n",
    "sns.set_theme(style=\"ticks\", context=\"paper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Graph Results\n",
    "\n",
    "- Graph DF (SWP, Avg Clutering etc)\n",
    "- Node (Centrality, NT, Clustering etc)\n",
    "- Edge DF (Weight, Distance, NT Combo, Same NT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_responders():\n",
    "    slow_responders_shock = (\n",
    "        load_derived_generic(\"slow_ts_foot_shock_unit_responders_pre_to_shock.csv\")\n",
    "        [[\"neuron_id\", \"response\"]]\n",
    "        .rename(columns={\"response\": \"response_fs_slow\"})\n",
    "    )\n",
    "    fast_responders_first_window = (\n",
    "        load_derived_generic(\"fast_fs_foot_shock_unit_responders.csv\")\n",
    "        [[\"neuron_id\", \"fs_fast_response\"]]\n",
    "    )\n",
    "    fast_responders_second_window = (\n",
    "        load_derived_generic(\"fast_fs_foot_shock_unit_responders_second_window.csv\")\n",
    "        [[\"neuron_id\", \"response_second_window\"]]\n",
    "    )\n",
    "    neuron_types = load_derived_generic(\"neuron_types.csv\")[[\"neuron_id\", \"neuron_type\", \"session_name\", \"group\"]]\n",
    "    df_responders = (\n",
    "        slow_responders_shock\n",
    "        .merge(fast_responders_first_window, how=\"outer\")\n",
    "        .merge(fast_responders_second_window, how=\"outer\")\n",
    "        .merge(neuron_types, how=\"left\")\n",
    "    )\n",
    "    return df_responders\n",
    "\n",
    "\n",
    "def get_graph_stats(session_name, bin_width, graph_transformer, shuffle):\n",
    "        graph_attrs = GraphAttributes(distance_from_edge=\"bounded\")\n",
    "        node_attrs = NodeAttributes()\n",
    "        loader = SpontaneousActivityLoader(\n",
    "            session_name=session_name, bin_width=bin_width, block=\"pre\", t_start=0, t_stop=1800, \n",
    "            shuffle=shuffle\n",
    "        )\n",
    "        preprocessor = InteractionsPreprocessor(z=False)\n",
    "        pairwise = PairwiseCorr(rectify=True)\n",
    "        spikes = preprocessor(loader())\n",
    "        df_affinity = (\n",
    "            pairwise.fit(spikes)\n",
    "            .get_adjacency_df()\n",
    "        )\n",
    "        G = df_to_graph(df_affinity, rename_nodes=True)\n",
    "        graph_stats = graph_attrs.get_graph_attributes(G).assign(\n",
    "            session_name=session_name,  bin_width=bin_width, shuffle=shuffle)\n",
    "        node_stats = node_attrs.get_node_attributes(G, node_name=\"neuron_id\").assign(\n",
    "            session_name=session_name,  bin_width=bin_width, shuffle=shuffle\n",
    "        )\n",
    "        edge_stats = (\n",
    "            graph_transformer\n",
    "            .graph_to_edge_df(G)\n",
    "            .assign(session_name=session_name, bin_width=bin_width, shuffle=shuffle)\n",
    "        )\n",
    "        return graph_stats, node_stats, edge_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_types = load_derived_generic(\"neuron_types.csv\")\n",
    "df_ensembles = (\n",
    "    load_derived_generic(\"ensembles/spont - ensembles - true.csv\")\n",
    "    .assign(in_ensemble = lambda x: np.where(x[\"ensemble_id\"] == -1, False, True))\n",
    ")\n",
    "df_responders = load_responders()\n",
    "df_distance = load_distances()\n",
    "sessions = neuron_types[\"session_name\"].dropna().unique()\n",
    "\n",
    "g_transform = GraphTransformer(\n",
    "    relabel_nodes=True,\n",
    "    weight_attr=\"weight\",\n",
    "    neuron_types=neuron_types,\n",
    "    df_distance=df_distance,\n",
    "    df_ensemble=df_ensembles,\n",
    ")\n",
    "\n",
    "graph_dfs = []\n",
    "node_dfs = []\n",
    "edge_dfs = []\n",
    "\n",
    "for shuffle in [True, False]:\n",
    "    for bin_width in [0.05, 0.1, 0.5, 1]:\n",
    "        for session in sessions:\n",
    "            graph_stats, node_stats, edge_stats = get_graph_stats(session, bin_width, g_transform, shuffle=shuffle)\n",
    "            graph_dfs.append(graph_stats)\n",
    "            node_dfs.append(node_stats)\n",
    "            edge_dfs.append(edge_stats)\n",
    "\n",
    "df_graph = (\n",
    "    pd.concat(graph_dfs)\n",
    "    .reset_index(drop=True)\n",
    "    .merge(neuron_types[[\"session_name\", \"group\"]].drop_duplicates(),)\n",
    ")\n",
    "\n",
    "df_node = (\n",
    "    pd.concat(node_dfs)\n",
    "    .reset_index(drop=True)\n",
    "    .merge(neuron_types[[\"neuron_id\", \"neuron_type\", \"group\"]])\n",
    "    .merge(df_ensembles[[\"neuron_id\", \"in_ensemble\"]])\n",
    ")\n",
    "df_edge = (\n",
    "    pd.concat(edge_dfs)\n",
    "    .reset_index(drop=True)\n",
    "    .merge(neuron_types[[\"session_name\", \"group\"]].drop_duplicates(),)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = Config.derived_data_dir / \"graph\"\n",
    "dd.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_graph.to_parquet(dd / \"spont - graph.parquet\", index=False)\n",
    "df_node.to_parquet(dd / \"spont - node.parquet\", index=False)\n",
    "df_edge.to_parquet(dd / \"spont - edge.parquet\", index=False)\n",
    "df_responders.to_parquet(dd / \"spont - responders.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ssri')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43cbdb6d61dab472ca36965b8e063b8466d44641e4bc0dd430fcfe888de07997"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
